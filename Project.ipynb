{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon AWS Library\n",
    "import boto3\n",
    "\n",
    "# for runtime logger\n",
    "import time\n",
    "\n",
    "# import pandas for dataframe manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# H3 index package\n",
    "from h3 import h3\n",
    "\n",
    "import json, requests, odf\n",
    "from random import uniform, randint\n",
    "from math import cos, radians\n",
    "\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize runtime log\n",
    "start_time = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup AWS login and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS credentials, region, and S3 Bucket name\n",
    "# If these credentials were more than dummy credentials, using a keyring would be better, to not expose credentials on a public repo.\n",
    "\n",
    "BUCKET_NAME = 'cct-ds-code-challenge-input-data'\n",
    "REGION = 'af-south-1'\n",
    "ACCESS_KEY = 'AKIAYH57YDEWMHW2ESH2'\n",
    "SECRET_ACCESS_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    region_name = REGION,\n",
    "    aws_access_key_id= ACCESS_KEY,\n",
    "    aws_secret_access_key= SECRET_ACCESS_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AWS S3 Select to retrieve resolution 8 indices.\n",
    "\n",
    "response = s3.select_object_content(\n",
    "    Bucket = BUCKET_NAME,\n",
    "    Key = 'city-hex-polygons-8-10.geojson',\n",
    "    ExpressionType = 'SQL',\n",
    "    Expression = \"SELECT * FROM S3Object[*].features[*] f WHERE f.properties.resolution = 8\",\n",
    "    InputSerialization = {'JSON':{'Type':'DOCUMENT'}},\n",
    "    OutputSerialization = {'JSON':{}},\n",
    ")\n",
    "\n",
    "with open('My_city-hex-polygons-8.geojson', 'w') as f:\n",
    "    for m in response['Payload']:\n",
    "        if 'Records' in m:\n",
    "            records = m['Records']['Payload'].decode('utf-8')\n",
    "            f.writelines(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete runtime log\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download geojson\n",
    "\n",
    "with open('city-hex-polygons-8.geojson', 'wb') as f:\n",
    "    s3.download_fileobj('cct-ds-code-challenge-input-data', 'city-hex-polygons-8.geojson', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation checks\n",
    "\n",
    "# Need to implement a check, like comparing the number of rows of data in each file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "\n",
    "# Intialize runtime log\n",
    "start_time = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing sr.csv for join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AWS S3 select to download sr.csv\n",
    "\n",
    "response = s3.select_object_content(\n",
    "    Bucket = BUCKET_NAME,\n",
    "    Key = 'sr.csv.gz',\n",
    "    ExpressionType = 'SQL',\n",
    "    Expression = \"SELECT * FROM S3Object\",\n",
    "    InputSerialization = {'CompressionType': 'GZIP','CSV':{'FileHeaderInfo': 'NONE'}},\n",
    "    OutputSerialization = {'CSV':{}},\n",
    ")\n",
    "\n",
    "with open('sr.csv', 'w') as f:\n",
    "    for m in response['Payload']:\n",
    "        if 'Records' in m:\n",
    "            records = m['Records']['Payload'].decode('utf-8')\n",
    "            f.writelines(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in sr.csv\n",
    "\n",
    "df_sr = pd.read_csv('sr.csv')\n",
    "df_sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab H3 indices for relevant latitude and longitude at resolution 8\n",
    "\n",
    "df_sr['H3'] = df_sr.apply(lambda x: h3.geo_to_h3(x.latitude, x.longitude,8), axis=1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing city-hex-polygons-8.geojson for join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "\n",
    "f = open('city-hex-polygons-8.geojson','r')\n",
    "g = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON into a DF\n",
    "h3_json = json.loads(g)\n",
    "df_h3 = pd.DataFrame(h3_json['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract H3 index for join\n",
    "\n",
    "df_h3['H3'] = df_h3['properties'].apply(lambda x: x['index'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the join on H3 indices\n",
    "\n",
    "df_sr_hex = pd.merge(df_sr,df_h3,how='left',left_on='H3', right_on='H3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete runtime log\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "\n",
    "# Intialize runtime log\n",
    "start_time = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine centroid of Bellville South\n",
    "\n",
    "Using OpenStreetMap API. The API documentation claims they return centroid coordinates for the given region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://nominatim.openstreetmap.org/search.php?q=bellville+south&format=jsonv2'\n",
    "response = requests.get(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates for Bellville South Centroid\n",
    "\n",
    "Bel_South = [float(data[0]['lat']),float(data[0]['lon'])]\n",
    "print(Bel_South)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download sr_hex.csv using AWS C3 Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sr_hex.csv\n",
    "\n",
    "response = s3.select_object_content(\n",
    "    Bucket = BUCKET_NAME,\n",
    "    Key = 'sr_hex.csv.gz',\n",
    "    ExpressionType = 'SQL',\n",
    "    Expression = \"SELECT * FROM S3Object\",\n",
    "    InputSerialization = {'CompressionType': 'GZIP','CSV':{'FileHeaderInfo': 'NONE'}},\n",
    "    OutputSerialization = {'CSV':{}},\n",
    ")\n",
    "\n",
    "with open('sr_hex.csv', 'w') as f:\n",
    "    for m in response['Payload']:\n",
    "        if 'Records' in m:\n",
    "            records = m['Records']['Payload'].decode('utf-8')\n",
    "            f.writelines(records)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: Distance within 1 minute\n",
    "\n",
    "The decimal difference between the two points should be less than 1/60 for both latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_a_minute(coord1, coord2):\n",
    "    lat1, lon1 = coord1\n",
    "    lat2, lon2 = coord2\n",
    "    return abs(lat1 - lat2) < 1/60 and abs(lon1 - lon2) < 1/60"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in sr_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sr = pd.read_csv('sr_hex.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply function and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sr['within_minute'] = df_sr.apply(lambda x: within_a_minute(Bel_South, [x['latitude'], x['longitude']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sr_BS = df_sr[df_sr['within_minute'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: subset of SR data less than a minute from Bellville South.\n",
    "\n",
    "df_sr_BS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and read wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://www.capetown.gov.za/_layouts/OpenDataPortalHandler/DownloadHandler.ashx?DocumentName=Wind_direction_and_speed_2020.ods&DatasetDocument=https%3A%2F%2Fcityapps.capetown.gov.za%2Fsites%2Fopendatacatalog%2FDocuments%2FWind%2FWind_direction_and_speed_2020.ods'\n",
    "response = requests.get(endpoint) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind = pd.read_excel(response.content,engine='odf',skiprows=2) # skip first two rows\n",
    "df_wind = df_wind.iloc[:-8] # remove last 8 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind = df_wind[['Date & Time','Bellville South AQM Site', 'Bellville South AQM Site.1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind.columns = ['Date & Time', 'BS Wind Dir_Deg', 'BS Wind Speed_m/s']\n",
    "df_wind = df_wind.iloc[2:,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfrom *Wind data* date column to the correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind['Date & Time'] = df_wind['Date & Time'].astype('datetime64[h]')\n",
    "df_wind['Date & Time']  = df_wind['Date & Time'].dt.tz_localize('Africa/Johannesburg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfrom *Service request* date column to the correct data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sr_BS['Created Time Hour'] = df_sr_BS['creation_timestamp'].astype('datetime64[h]')\n",
    "df_sr_BS['Created Time Hour'] = df_sr_BS['Created Time Hour'].dt.tz_localize('UTC').dt.tz_convert('Africa/Johannesburg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_sr_BS,df_wind,how='left',left_on='Created Time Hour', right_on='Date & Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: merged wind speed and direction data\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete runtime log\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce location accuracy, within 500 meters\n",
    "\n",
    "We achieve this by shifting the longitude and latitude a random number of meters (<500) for each coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location reduction functions\n",
    "\n",
    "\n",
    "def reduce_accuracy_lat(lat):\n",
    "    # Convert lat to km\n",
    "    lat_km = lat * 111\n",
    "    \n",
    "    # Generate random values between -0.5 and 0.5\n",
    "    lat_offset = uniform(-0.5, 0.5)\n",
    "    \n",
    "    # Add offset to lat\n",
    "    new_lat_km = lat_km + (lat_offset / 1000)\n",
    "    \n",
    "    # Convert back to degrees\n",
    "    new_lat = new_lat_km / 111\n",
    "    \n",
    "    return new_lat\n",
    "\n",
    "def reduce_accuracy_lon(lat, lon):\n",
    "    # Convert lon to km\n",
    "    lon_km = lon * 111 * cos(radians(lat))\n",
    "    \n",
    "    # Generate random values between -0.5 and 0.5\n",
    "    lon_offset = uniform(-0.5, 0.5)\n",
    "    \n",
    "    # Add offset to lon\n",
    "    new_lon_km = lon_km + (lon_offset / 1000 / cos(radians(lat)))\n",
    "    \n",
    "    # Convert back to degrees\n",
    "    new_lon = new_lon_km / (111 * cos(radians(lat)))\n",
    "    \n",
    "    return new_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new coords\n",
    "\n",
    "df_location['latitude_new'] = df_location['latitude'].apply(lambda x: reduce_accuracy_lat(x))\n",
    "df_location['longitude_new'] = df_location.apply(lambda x: reduce_accuracy_lon(x['latitude'], x['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce temporal accuracy\n",
    "\n",
    "Same as above, we achieve this by shifting the time a random number of hours (<6) for each time value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_time_accuracy(t):\n",
    "    time_offset = randint(-6, 6)\n",
    "    new_time = t + dt.timedelta(hours=time_offset)\n",
    "    return new_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal = df_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal['creation_timestamp'] = df_temporal['creation_timestamp'].astype('datetime64')\n",
    "df_temporal['completion_timestamp'] = df_temporal['completion_timestamp'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal['creation_timestamp2'] = df_temporal['creation_timestamp'].apply(lambda x: reduce_time_accuracy(x))\n",
    "df_temporal['completion_timestamp2'] = df_temporal['completion_timestamp'].apply(lambda x: reduce_time_accuracy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal['creation_timestamp2'] = df_temporal['creation_timestamp2'].dt.tz_localize('UTC').dt.tz_convert('Africa/Johannesburg')\n",
    "df_temporal['completion_timestamp2'] = df_temporal['completion_timestamp2'].dt.tz_localize('UTC').dt.tz_convert('Africa/Johannesburg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick Anonymous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_temporal[['notification_number', 'reference_number', 'directorate', 'department', 'branch',\n",
    "       'section', 'code_group', 'code', 'cause_code_group', 'cause_code',\n",
    "       'official_suburb', 'h3_level8_index', 'BS Wind Dir_Deg',\n",
    "       'BS Wind Speed_m/s', 'latitude_new', 'longitude_new',\n",
    "       'creation_timestamp2', 'completion_timestamp2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "\n",
    "df_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final comment:\n",
    "\n",
    "Besides anonymizing dates and GPS coordinates, there are no other columns that give away personally identifying information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
